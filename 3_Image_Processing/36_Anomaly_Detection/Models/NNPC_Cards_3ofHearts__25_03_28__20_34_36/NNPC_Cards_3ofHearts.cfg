[wrn_50_2_2_bnmerge]
Type = "Net"
batch = 1
Beta_1 = 0.9990
Beta_2 = 0.9990
k = 0.0000
Weight_Decay(L1) = 0.0000E+0
Weight_Decay(L2) = 0.0000E+0
LR0 = 0.0000E+0
Optimizer = "SGD"
Data_Sampling = "Random"
LR_Policy = "Manual"
Labels = ""
Mean_R = 0.3995
Mean_G = 0.2878
Mean_B = 0.2493
Var_R = 0.4426
Var_G = 0.3521
Var_B = 0.2961
Interpolation_Type = "Bi-Linear"
Image_Threshold = 11.1610
Pixel_Threshold = 2.5442
Pixel_Range_Min = 1.4061
Pixel_Range_Max = 13.1277

[input3d]
Type = "Input3D"
Channels = 3
Height = 320
Width = 320
Shifts = "0,0,0"
Scales = "1,1,1"
Data_Type = "SGL"

[conv2d]
Type = "Conv2D"
Filters = 64
Size = 7
Stride = 2
Pad_Size = 3
BN = FALSE
Has_Bias = TRUE
Activation = "ReLU"
Pad_Type = "Pad_Size"
Input_Layers = "input3d"

[maxpool]
Type = "MaxPool"
Size(V) = 3
Size(H) = 3
Stride(V) = 2
Stride(H) = 2
Pad_Size(V) = 1
Pad_Size(H) = 1
Pad_Type = "Pad_Size"
Input_Layers = "conv2d"

[conv2d_3]
Type = "Conv2D"
Filters = 128
Size = 1
Stride = 1
Pad_Size = 0
BN = FALSE
Has_Bias = TRUE
Activation = "ReLU"
Pad_Type = "Pad_Size"
Input_Layers = "maxpool"

[conv2d_4]
Type = "Conv2D"
Filters = 128
Size = 3
Stride = 1
Pad_Size = 1
BN = FALSE
Has_Bias = TRUE
Activation = "ReLU"
Pad_Type = "Pad_Size"
Input_Layers = "conv2d_3"

[conv2d_5]
Type = "Conv2D"
Filters = 256
Size = 1
Stride = 1
Pad_Size = 0
BN = FALSE
Has_Bias = TRUE
Activation = "None"
Pad_Type = "Pad_Size"
Input_Layers = "conv2d_4"

[conv2d_6]
Type = "Conv2D"
Filters = 256
Size = 1
Stride = 1
Pad_Size = 0
BN = FALSE
Has_Bias = TRUE
Activation = "None"
Pad_Type = "Valid"
Input_Layers = "maxpool"

[shortcut]
Type = "SCut"
Activation = "ReLU"
Input_Layers = "conv2d_5,conv2d_6"

[conv2d_8]
Type = "Conv2D"
Filters = 128
Size = 1
Stride = 1
Pad_Size = 0
BN = FALSE
Has_Bias = TRUE
Activation = "ReLU"
Pad_Type = "Pad_Size"
Input_Layers = "shortcut"

[conv2d_9]
Type = "Conv2D"
Filters = 128
Size = 3
Stride = 1
Pad_Size = 1
BN = FALSE
Has_Bias = TRUE
Activation = "ReLU"
Pad_Type = "Pad_Size"
Input_Layers = "conv2d_8"

[conv2d_10]
Type = "Conv2D"
Filters = 256
Size = 1
Stride = 1
Pad_Size = 0
BN = FALSE
Has_Bias = TRUE
Activation = "None"
Pad_Type = "Pad_Size"
Input_Layers = "conv2d_9"

[shortcut_11]
Type = "SCut"
Activation = "ReLU"
Input_Layers = "conv2d_10,shortcut"

[conv2d_12]
Type = "Conv2D"
Filters = 128
Size = 1
Stride = 1
Pad_Size = 0
BN = FALSE
Has_Bias = TRUE
Activation = "ReLU"
Pad_Type = "Pad_Size"
Input_Layers = "shortcut_11"

[conv2d_13]
Type = "Conv2D"
Filters = 128
Size = 3
Stride = 1
Pad_Size = 1
BN = FALSE
Has_Bias = TRUE
Activation = "ReLU"
Pad_Type = "Pad_Size"
Input_Layers = "conv2d_12"

[conv2d_14]
Type = "Conv2D"
Filters = 256
Size = 1
Stride = 1
Pad_Size = 0
BN = FALSE
Has_Bias = TRUE
Activation = "None"
Pad_Type = "Pad_Size"
Input_Layers = "conv2d_13"

[shortcut_15]
Type = "SCut"
Activation = "ReLU"
Input_Layers = "conv2d_14,shortcut_11"

[conv2d_16]
Type = "Conv2D"
Filters = 256
Size = 1
Stride = 1
Pad_Size = 0
BN = FALSE
Has_Bias = TRUE
Activation = "ReLU"
Pad_Type = "Pad_Size"
Input_Layers = "shortcut_15"

[conv2d_17]
Type = "Conv2D"
Filters = 256
Size = 3
Stride = 2
Pad_Size = 1
BN = FALSE
Has_Bias = TRUE
Activation = "ReLU"
Pad_Type = "Pad_Size"
Input_Layers = "conv2d_16"

[conv2d_18]
Type = "Conv2D"
Filters = 512
Size = 1
Stride = 1
Pad_Size = 0
BN = FALSE
Has_Bias = TRUE
Activation = "None"
Pad_Type = "Pad_Size"
Input_Layers = "conv2d_17"

[conv2d_19]
Type = "Conv2D"
Filters = 512
Size = 1
Stride = 2
Pad_Size = 0
BN = FALSE
Has_Bias = TRUE
Activation = "None"
Pad_Type = "Valid"
Input_Layers = "shortcut_15"

[shortcut_20]
Type = "SCut"
Activation = "ReLU"
Input_Layers = "conv2d_18,conv2d_19"

[conv2d_21]
Type = "Conv2D"
Filters = 256
Size = 1
Stride = 1
Pad_Size = 0
BN = FALSE
Has_Bias = TRUE
Activation = "ReLU"
Pad_Type = "Pad_Size"
Input_Layers = "shortcut_20"

[conv2d_22]
Type = "Conv2D"
Filters = 256
Size = 3
Stride = 1
Pad_Size = 1
BN = FALSE
Has_Bias = TRUE
Activation = "ReLU"
Pad_Type = "Pad_Size"
Input_Layers = "conv2d_21"

[conv2d_23]
Type = "Conv2D"
Filters = 512
Size = 1
Stride = 1
Pad_Size = 0
BN = FALSE
Has_Bias = TRUE
Activation = "None"
Pad_Type = "Pad_Size"
Input_Layers = "conv2d_22"

[shortcut_24]
Type = "SCut"
Activation = "ReLU"
Input_Layers = "conv2d_23,shortcut_20"

[conv2d_25]
Type = "Conv2D"
Filters = 256
Size = 1
Stride = 1
Pad_Size = 0
BN = FALSE
Has_Bias = TRUE
Activation = "ReLU"
Pad_Type = "Pad_Size"
Input_Layers = "shortcut_24"

[conv2d_26]
Type = "Conv2D"
Filters = 256
Size = 3
Stride = 1
Pad_Size = 1
BN = FALSE
Has_Bias = TRUE
Activation = "ReLU"
Pad_Type = "Pad_Size"
Input_Layers = "conv2d_25"

[conv2d_27]
Type = "Conv2D"
Filters = 512
Size = 1
Stride = 1
Pad_Size = 0
BN = FALSE
Has_Bias = TRUE
Activation = "None"
Pad_Type = "Pad_Size"
Input_Layers = "conv2d_26"

[shortcut_28]
Type = "SCut"
Activation = "ReLU"
Input_Layers = "conv2d_27,shortcut_24"

[conv2d_29]
Type = "Conv2D"
Filters = 256
Size = 1
Stride = 1
Pad_Size = 0
BN = FALSE
Has_Bias = TRUE
Activation = "ReLU"
Pad_Type = "Pad_Size"
Input_Layers = "shortcut_28"

[conv2d_30]
Type = "Conv2D"
Filters = 256
Size = 3
Stride = 1
Pad_Size = 1
BN = FALSE
Has_Bias = TRUE
Activation = "ReLU"
Pad_Type = "Pad_Size"
Input_Layers = "conv2d_29"

[conv2d_31]
Type = "Conv2D"
Filters = 512
Size = 1
Stride = 1
Pad_Size = 0
BN = FALSE
Has_Bias = TRUE
Activation = "None"
Pad_Type = "Pad_Size"
Input_Layers = "conv2d_30"

[shortcut_32]
Type = "SCut"
Activation = "ReLU"
Input_Layers = "conv2d_31,shortcut_28"

[conv2d_33]
Type = "Conv2D"
Filters = 512
Size = 1
Stride = 1
Pad_Size = 0
BN = FALSE
Has_Bias = TRUE
Activation = "ReLU"
Pad_Type = "Pad_Size"
Input_Layers = "shortcut_32"

[NNPC_AvgPool_L33]
Type = "AvgPool"
Size(V) = 3
Size(H) = 3
Stride(V) = 1
Stride(H) = 1
Pad_Size(V) = 1
Pad_Size(H) = 1
Input_Layers = "conv2d_33"

[NNPC_MemBank]
Type = "Conv2D"
Filters = 2000
Size = 1
Stride = 1
Pad_Size = 0
BN = FALSE
Has_Bias = FALSE
Activation = "None"
Pad_Type = "Valid"
Input_Layers = "NNPC_AvgPool_L33"

[Loss]
Type = "MSE"